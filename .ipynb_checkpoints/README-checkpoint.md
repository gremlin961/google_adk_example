# Example Agent Workflow using Google's ADK

This Jupyter notebook demonstrates how to build an agentic workflow using Google's Agent Development Kit (ADK). It showcases a practical example involving customer support for installing a Nest thermostat.

**Key Concepts Demonstrated:**

* **Agent Creation:** Defining multiple agents with specific roles and instructions (RAG agent, Reasoning agent, Notes agent, Root agent).
* **Tool Definition:** Creating Python functions that agents can use as tools to interact with external systems or perform specific tasks (e.g., `create_ticket`, `add_note`, `add_file_to_session`, `get_gcs_uri`).
* **Vertex AI Integration:** Utilizing Vertex AI services, specifically:
    * **Generative Models (Gemini):** Powering the agents' reasoning and response generation.
    * **RAG Engine (Retrieval-Augmented Generation):** Creating and querying a corpus of documents (PDFs in this case) to find relevant information for grounding agent responses.
    * **Google Cloud Storage (GCS):** Storing documents for the RAG Engine.
* **Agent Orchestration:** Using a root agent to manage the flow and delegate tasks to specialized child agents (`flow='auto'`).
* **Session Management:** Maintaining context and shared information across agent interactions using `InMemorySessionService` and `InMemoryArtifactService`.
* **Mock API Interaction:** Simulating interaction with an external ticketing system using Python's `requests` library.

**Workflow Overview:**

1.  **Environment Setup:** Configures project ID, location, GCS bucket details, and mock ticket server URL. Initializes Vertex AI.
2.  **Data Preparation:**
    *   Uploads relevant PDF documentation (Nest installation guides) to a specified GCS bucket.
    *   Creates or verifies the existence of a Vertex AI RAG Corpus using these documents.
3.  **Function/Tool Definition:** Defines Python functions for:
    *   Interacting with the mock ticketing system (`create_ticket`, `add_note`).
    *   Querying the RAG Engine (`get_gcs_uri`).
    *   Adding files (GCS URIs) to the agent session context (`add_file_to_session`).
    *   Managing the RAG Corpus (`create_rag_corpora`, `delete_rag_corpora`).
4.  **Agent Definition:**
    *   **`rag_agent`:** Uses `get_gcs_uri` tool to find the GCS URI of the most relevant support document based on the user's query.
    *   **`reasoning_agent`:** Uses the context (including files added via `add_file_to_session`) to generate troubleshooting steps based on the provided documentation.
    *   **`notes_agent`:** Uses the `add_note` tool to add generated notes (like troubleshooting steps) to the mock ticket system.
    *   **`root_agent`:** Orchestrates the workflow. It receives the user query, calls the `rag_agent` to find relevant documents, potentially uses `add_file_to_session` to add them to the context, calls the `reasoning_agent` to generate steps, and finally calls the `notes_agent` to log the outcome.
5.  **Execution:**
    *   Initializes the `Runner` with the `root_agent` and session/artifact services.
    *   Creates a session.
    *   Runs prompts through the `run_prompt` function, simulating a user interaction:
        *   User asks for help installing a Nest thermostat.
        *   The root agent delegates to the `rag_agent` to find relevant manuals via RAG.
        *   The root agent receives the GCS URIs.
        *   The user (or root agent in a more complex flow) asks to define troubleshooting steps.
        *   The root agent adds the relevant guide (using its GCS URI) to the session context via `add_file_to_session`.
        *   The root agent delegates to the `reasoning_agent`.
        *   The `reasoning_agent` reads the guide from the context and generates step-by-step instructions.
        *   The user (or root agent) asks to add these steps to the ticket.
        *   The root agent delegates to the `notes_agent`.
        *   The `notes_agent` calls the `add_note` tool, sending the generated steps and ticket details to the mock ticket server API.
6.  **Verification:** Suggests checking the output file (`notes.txt`) generated by the mock `ticket_server.py` to see the final notes added by the agent.

**Prerequisites:**

*   Google Cloud Project with Vertex AI API enabled.
*   Authentication configured for Google Cloud (e.g., `gcloud auth application-default login`).
*   Python environment with necessary libraries installed:
    *   `google-cloud-aiplatform`
    *   `google-adk` (Note: The notebook uses preview features)
    *   `google-cloud-storage`
    *   `requests`
    *   `ipython`
    *   `google-genai` (Potentially, though configured to use Vertex AI)
*   A running instance of the mock `ticket_server.py` accessible via the configured `ticket_server_url`.
*   Nest documentation PDF files placed in the `local_documents` directory (e.g., `./nest_docs/`).
*   A running instance of the mock `ticket_server.py` accessible via the configured `ticket_server_url`. **(See Setup Mock Ticket Server section below)**
*   Nest documentation PDF files placed in the `local_documents` directory (e.g., `./nest_docs/`).

---

## Setup Mock Ticket Server (GCE Instance)

The notebook interacts with a simple mock ticketing API provided by `ticket_server.py`. You need to run this server on a machine accessible from where you run the notebook. A small Google Compute Engine (GCE) instance is a suitable option.

**1. Create a GCE Instance:**

*   **Navigate to GCE:** Go to the Google Cloud Console -> Compute Engine -> VM instances.
*   **Create Instance:** Click "CREATE INSTANCE".
*   **Name:** Give it a descriptive name (e.g., `ticket-server-vm`).
*   **Region/Zone:** Choose a region and zone (e.g., `us-central1-a`).
*   **Machine Configuration:**
    *   **Series:** E2 (cost-effective)
    *   **Machine type:** `e2-micro` or `e2-small` should be sufficient for this simple server.
*   **Boot Disk:**
    *   **Operating system:** Choose a Linux distribution (e.g., Debian 11 or Ubuntu 22.04 LTS).
    *   **Size:** The default (10 GB) is likely fine.
*   **Firewall:**
    *   Check **"Allow HTTP traffic"**. This opens port 80. *If you plan to use a different port (like 8000 as specified in the notebook), you'll need to add a specific firewall rule later.*
*   **Create:** Click "Create". Wait for the instance to be provisioned.

**2. Configure Firewall (If using a port other than 80):**

*   If your `ticket_server_url` in the notebook uses a port like `8000`:
    *   Go to VPC network -> Firewall in the Cloud Console.
    *   Click "CREATE FIREWALL RULE".
    *   **Name:** `allow-ticket-server-port` (or similar).
    *   **Network:** `default` (unless you use a custom VPC).
    *   **Targets:** `All instances in the network` (or use `Specified target tags` and add a tag like `ticket-server` to your VM).
    *   **Source filter:** `IP ranges`.
    *   **Source IP ranges:** `0.0.0.0/0` (allows access from any IP - **Note:** For production, restrict this to known IPs).
    *   **Protocols and ports:** Select `Specified protocols and ports`, check `TCP`, and enter the port number (e.g., `8000`).
    *   Click "Create".

**3. SSH into the Instance:**

*   Go back to Compute Engine -> VM instances.
*   Find your `ticket-server-vm` instance.
*   Click the "SSH" button to open a browser-based SSH terminal.

**4. Install Dependencies:**

*   Inside the SSH terminal, run the following commands:

    ```bash
    # Update package lists
    sudo apt update

    # Install python3, pip, and venv
    sudo apt install python3 python3-pip python3-venv -y

    # Create a directory for the server
    mkdir ticket-app
    cd ticket-app

    # Create a virtual environment
    python3 -m venv venv
    source venv/bin/activate

    # Clone your repository (replace with your actual repo URL)
    # OR use gcloud compute scp to copy the files if not using git
    git clone <your-repository-url> .
    # Example using scp (run from your local machine, not the VM):
    # gcloud compute scp requirements.txt ticket_server.py ticket-server-vm:~/ticket-app/ --zone=us-central1-a

    # Install required Python packages
    pip install -r requirements.txt
    ```

**5. Run the Ticket Server:**

*   Ensure you are in the `ticket-app` directory and the virtual environment (`venv`) is active.
*   Run the FastAPI server using uvicorn:

    ```bash
    # Run on port 8000 (or the port you configured) and accessible externally
    uvicorn ticket_server:app --host 0.0.0.0 --port 8000
    ```
    *   `--host 0.0.0.0` makes it listen on all available network interfaces.
    *   `--port 8000` specifies the port (match the firewall rule and the notebook's `ticket_server_url`).

*   The server should now be running. Keep this SSH terminal open.

**6. Get the Instance's External IP:**

*   Go back to the VM instances list in the Cloud Console.
*   Find the **External IP** address for your `ticket-server-vm`.

**7. Update Notebook Configuration:**

*   Go back to your Jupyter notebook.
*   In cell `[3]`, update the `ticket_server_url` variable to use the External IP address of your GCE instance and the correct port:

    ```python
    # Example:
    ticket_server_url = "http://<YOUR_INSTANCE_EXTERNAL_IP>:8000"
    ```

---

## How to Run the Notebook

1.  Clone the repository or download the notebook and associated files (`ticket_server.py`, PDF documents, `requirements.txt`).
2.  Set up and run the mock `ticket_server.py` on a GCE instance (or other accessible machine) following the steps above.
3.  Update the environment variables in cell `[3]` (especially `project_id`, `corpa_document_bucket`, `local_documents`, and the verified `ticket_server_url`).
4.  Ensure your local machine or environment where you run the notebook is authenticated to Google Cloud (`gcloud auth application-default login`).
5.  Run the Jupyter notebook cells sequentially.
6.  Observe the output of the `run_prompt` cells to see the agent interactions and generated responses.
7.  Check the `notes.txt` file created in the `/ticket-app` directory on your GCE instance to verify the final output logged by the `notes_agent`.

**Note:** This notebook utilizes preview features of the Google ADK and Vertex AI RAG Engine. APIs and functionality might change. Remember to stop or delete your GCE instance when you are finished to avoid incurring unnecessary costs.