{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f818530-d1dc-4ebf-bf9a-f6f536879bf8",
   "metadata": {},
   "source": [
    "Copyright 2024 Google, LLC. This software is provided as-is,\n",
    "without warranty or representation for any use or purpose. Your\n",
    "use of it is subject to your agreement with Google.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "   http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\n",
    "# Example Agent Workflow using Google's ADK\n",
    "\n",
    "This notebook provides an example of building an agentic workflow with Google's new ADK. For more information please visit https://google.github.io/adk-docs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intro-markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent Nest Support System with Vertex AI RAG and ADK\n",
    "\n",
    "This notebook demonstrates building a customer support agent system using Vertex AI's Generative Models, RAG (Retrieval-Augmented Generation) Engine, and the Agent Development Kit (ADK).\n",
    "\n",
    "The system includes:\n",
    "1.  **RAG Setup:** Ingesting Nest support documents into a Vertex AI RAG Corpus.\n",
    "2.  **Tool Definitions:** Functions to interact with a mock ticketing system and manage files.\n",
    "3.  **Sub-Agent Definitions:** Specialized agents for RAG retrieval, reasoning/process definition, and adding notes to tickets.\n",
    "4.  **Root Agent Definition:** An orchestrator agent that delegates tasks to the sub-agents.\n",
    "5.  **Interaction:** Running a sample conversation with the agent team."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-deps-markdown",
   "metadata": {},
   "source": [
    "## 0. Install Dependencies\n",
    "\n",
    "Install the necessary libraries for Vertex AI, Google Cloud, ADK, and HTTP requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-deps-code",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Core Vertex AI, RAG and Agent SDK\n",
    "!pip install --upgrade --quiet google-cloud-aiplatform google-cloud-storage requests google-cloud-discoveryengine\n",
    "!pip install --upgrade --quiet google-adk\n",
    "\n",
    "# Optional: For rendering markdown in output\n",
    "!pip install --upgrade --quiet IPython\n",
    "\n",
    "print(\"Dependencies installed/updated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-libs-markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "import-libs-code",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Vertex AI Modules\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, GenerationConfig, Part, Tool, ChatSession, FunctionDeclaration, grounding, GenerationResponse\n",
    "from vertexai.preview import rag\n",
    "\n",
    "# Vertex Agent Modules\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.artifacts.in_memory_artifact_service import InMemoryArtifactService\n",
    "from google.adk.tools.agent_tool import AgentTool\n",
    "\n",
    "\n",
    "# Vertex GenAI Modules\n",
    "import google.genai\n",
    "from google.genai import types\n",
    "\n",
    "# Google Cloud AI Platform Modules\n",
    "from google.cloud import aiplatform_v1beta1 as aiplatform # This module helps parse the info for delete_rag_corpa function\n",
    "from google.cloud import storage\n",
    "\n",
    "#Google BigQuery\n",
    "from google.cloud import bigquery\n",
    "\n",
    "\n",
    "# Other Python Modules\n",
    "#import base64\n",
    "#from IPython.display import Markdown\n",
    "import asyncio\n",
    "import requests\n",
    "import os\n",
    "from typing import List, Dict, TypedDict, Any\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701b9076-6af8-402b-860b-c417d4e5780b",
   "metadata": {},
   "source": [
    "Ignore warning messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8623395-c614-427b-b637-04b7f5cf915b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "**Important:** Update the `project_id`, `corpa_document_bucket`, `local_documents`, and `ticket_server_url` variables below with your specific values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "config-code",
   "metadata": {
    "Collapsed": "false",
    "jupyter": {
     "source_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_id = \"YOUR_PROJECT_ID\" # Your GCP Project ID\n",
    "location = \"global\" # You can leave this setting as global\n",
    "region = \"us-central1\" # Your region. This notebook has only been tested in us-central1\n",
    "\n",
    "corpa_name = \"nest-rag-corpus\" # This will be the display name of your RAG Engine corpus\n",
    "\n",
    "corpa_document_bucket = \"gs://YOUR_BUCKET_ID/nest/docs/\" # The GCS path to the files you want to ingest into your RAG Engine corpus\n",
    "bq_data_bucket = \"gs://YOUR_BUCKET_ID/wip/bq_import/\" # The GCS path to the files you want to ingest into your BQ datastore\n",
    "\n",
    "support_documents = \"./nest_docs/\" # Local directory containing Nest support files to copy\n",
    "bq_data = \"./bq_data/\" # Local directory containing BQ data files\n",
    "\n",
    "ticket_server_url = \"http://ticket01:8000\" # The url to the mock ticket system. This will be a GCE VM running the ticket_server.py web service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "init-vertex-markdown",
   "metadata": {},
   "source": [
    "## 3. Environment Setup and Vertex AI Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bc59be-1eab-4125-8cd0-d85792f49619",
   "metadata": {},
   "source": [
    "Set environment variables for Google libraries and initiate the vertex ai client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "init-vertex-code",
   "metadata": {
    "Collapsed": "false",
    "jupyter": {
     "source_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"1\"\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = project_id\n",
    "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d3a2315-45c2-4a87-a0b8-de428adbd2bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertexai.init(project=project_id, location=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gcs-setup-markdown",
   "metadata": {},
   "source": [
    "## 4. Google Cloud Storage Setup\n",
    "\n",
    "This function checks if the specified GCS bucket and folder exist, creates them if necessary, and uploads documents from the local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5e88b26-f815-49f2-aed9-a4a1c7e37734",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_bucket(bucket_path: str):\n",
    "    parsed_uri = urlparse(bucket_path)\n",
    "    bucket_name = parsed_uri.netloc\n",
    "    prefix = parsed_uri.path.lstrip('/')\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # Get the bucket object\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "    # Check if the bucket exists, create it if not\n",
    "    if not bucket.exists():\n",
    "        bucket.create()\n",
    "        print(f\"Bucket '{bucket_name}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Bucket '{bucket_name}' already exists.\")\n",
    "\n",
    "    # Create the folder prefix if it doesn't implicitly exist\n",
    "    if prefix:\n",
    "        blob_name = f\"{prefix}\" if prefix.endswith('/') else f\"{prefix}/\"\n",
    "        placeholder_blob = bucket.blob(blob_name + \".placeholder\")\n",
    "        if not placeholder_blob.exists():\n",
    "            placeholder_blob.upload_from_string('')\n",
    "            print(f\"Simulated folder '{bucket_path}' created.\")\n",
    "        else:\n",
    "            print(f\"Simulated folder '{bucket_path}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "011b9b02-92ae-4f62-b3c5-d81b1b2e782b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upload_files(folder_path: str, bucket_path: str):\n",
    "    parsed_uri = urlparse(bucket_path)\n",
    "    bucket_name = parsed_uri.netloc\n",
    "    prefix = parsed_uri.path.lstrip('/')\n",
    "    \n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # Get the bucket object\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "    if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "        for filename in os.listdir(folder_path):\n",
    "            local_file_path = os.path.join(folder_path, filename)\n",
    "            if os.path.isfile(local_file_path):\n",
    "                gcs_blob_name = f\"{prefix}{filename}\"\n",
    "                blob = bucket.blob(gcs_blob_name)\n",
    "                blob.upload_from_filename(local_file_path)\n",
    "                print(f\"Uploaded '{local_file_path}' to 'gs://{bucket_name}/{gcs_blob_name}'\")\n",
    "    else:\n",
    "        print(f\"Local directory '{folder_path}' does not exist or is not a directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04240941-b143-43ed-b618-9f71b0f3c93e",
   "metadata": {},
   "source": [
    "Create the Nest Support Document bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03b509aa-b954-47c4-b8e5-6f5cf9415924",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'YOUR_BUCKET_ID' already exists.\n",
      "Simulated folder 'gs://YOUR_BUCKET_ID/nest/docs/' already exists.\n"
     ]
    }
   ],
   "source": [
    "create_bucket(corpa_document_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7780b3fe-16fa-4559-a7b1-a69029507f95",
   "metadata": {},
   "source": [
    "Create the BQ Data bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1589aab4-b9c0-4d90-846a-1f2c69b78507",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'YOUR_BUCKET_ID' already exists.\n",
      "Simulated folder 'gs://YOUR_BUCKET_ID/wip/bq_import/' created.\n"
     ]
    }
   ],
   "source": [
    "create_bucket(bq_data_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d285ce3-d291-45e6-94f6-dba02915ac72",
   "metadata": {},
   "source": [
    "Upload the Nest support documents to the GCS bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38d76a29-3453-423a-aee7-7d0142275960",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded './nest_docs/Nest_Power_Connector_Installation_Guide.pdf' to 'gs://YOUR_BUCKET_ID/nest/docs/Nest_Power_Connector_Installation_Guide.pdf'\n",
      "Uploaded './nest_docs/nest-thermostat-gen3-install-guide-US.pdf' to 'gs://YOUR_BUCKET_ID/nest/docs/nest-thermostat-gen3-install-guide-US.pdf'\n",
      "Uploaded './nest_docs/nest-thermostat-e-install-guide.pdf' to 'gs://YOUR_BUCKET_ID/nest/docs/nest-thermostat-e-install-guide.pdf'\n"
     ]
    }
   ],
   "source": [
    "upload_files(support_documents, corpa_document_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639fa221-f168-4256-86d3-c10f9e611612",
   "metadata": {},
   "source": [
    "Upload the BQ data documents to the GCS bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f5a162c-dab1-467e-aed2-1036902404ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded './bq_data/product_data.avro' to 'gs://YOUR_BUCKET_ID/wip/bq_import/product_data.avro'\n"
     ]
    }
   ],
   "source": [
    "upload_files(bq_data, bq_data_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helper-funcs-markdown",
   "metadata": {},
   "source": [
    "## 5. Helper Functions\n",
    "\n",
    "Define functions for interacting with the agent, managing RAG corpora, and defining tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "agent-interact-func-code",
   "metadata": {
    "Collapsed": "false",
    "jupyter": {
     "source_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent interaction function `call_agent_async` defined.\n"
     ]
    }
   ],
   "source": [
    "# @title Define Agent Interaction Function\n",
    "async def call_agent_async(query: str, runner: Runner, user_id: str, session_id: str):\n",
    "    \"\"\"Sends a query to the agent runner and prints the final response.\"\"\"\n",
    "    #print(f\"\\n>>> User Query: {query}\")\n",
    "\n",
    "    # Prepare the user's message in ADK format\n",
    "    content = types.Content(role='user', parts=[types.Part(text=query)])\n",
    "\n",
    "    final_response_text = \"Agent did not produce a final response.\" # Default\n",
    "\n",
    "    try:\n",
    "        # Key Concept: run_async executes the agent logic and yields Events.\n",
    "        # We iterate through events to find the final answer.\n",
    "        async for event in runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n",
    "            # You can uncomment the line below to see *all* events during execution\n",
    "            # print(f\"  [Event] Author: {event.author}, Type: {type(event).__name__}, Final: {event.is_final_response()}, Content: {event.content}\")\n",
    "\n",
    "            # Key Concept: is_final_response() marks the concluding message for the turn.\n",
    "            if event.is_final_response():\n",
    "                if event.content and event.content.parts:\n",
    "                    # Assuming text response in the first part\n",
    "                    final_response_text = event.content.parts[0].text\n",
    "                elif event.actions and event.actions.escalate: # Handle potential errors/escalations\n",
    "                    final_response_text = f\"Agent escalated: {event.error_message or 'No specific message.'}\"\n",
    "                # Add more checks here if needed (e.g., specific error codes)\n",
    "                break # Stop processing events once the final response is found\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during agent execution: {e}\")\n",
    "        final_response_text = f\"Agent interaction failed with error: {e}\"\n",
    "\n",
    "    print(f\"Agent: {final_response_text}\") # Added \"Agent: \" prefix\n",
    "\n",
    "print(\"Agent interaction function `call_agent_async` defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "rag-manage-funcs-code",
   "metadata": {
    "Collapsed": "false",
    "jupyter": {
     "source_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG corpus management functions defined.\n"
     ]
    }
   ],
   "source": [
    "# @title Define RAG Corpus Management Functions\n",
    "\n",
    "# NOTE: The delete function is defined but not used in the main flow.\n",
    "# It can be useful for cleanup. It expects a pager object, which is\n",
    "# typically obtained from `rag.list_corpora()`.\n",
    "def delete_rag_corpora(rag_corpora_pager: aiplatform.services.vertex_rag_data_service.pagers.ListRagCorporaPager):\n",
    "    \"\"\"\n",
    "    Deletes all RAG corpora listed in the provided pager object.\n",
    "    USE WITH CAUTION! THIS WILL PERMANENTLY DELETE CORPORA.\n",
    "\n",
    "    Args:\n",
    "        rag_corpora_pager: The pager object from rag.list_corpora().\n",
    "    \"\"\"\n",
    "    names_list = []\n",
    "    print(\"Identifying corpora to delete...\")\n",
    "    try:\n",
    "        for rag_corpus_obj in rag_corpora_pager: # Iterate through the actual RagCorpus objects\n",
    "            if hasattr(rag_corpus_obj, 'name'):\n",
    "                print(f\" - Found corpus: {rag_corpus_obj.display_name} ({rag_corpus_obj.name})\")\n",
    "                names_list.append(rag_corpus_obj.name)\n",
    "            else:\n",
    "                print(f\" - Skipping object without a 'name' attribute: {rag_corpus_obj}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error iterating through corpora pager: {e}\")\n",
    "        return # Stop if we can't list them properly\n",
    "\n",
    "    if not names_list:\n",
    "        print(\"No corpora found to delete.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nStarting deletion process...\")\n",
    "    deleted_count = 0\n",
    "    failed_count = 0\n",
    "    for corpus_name_to_delete in names_list:\n",
    "        print(f\"Attempting to delete corpus: {corpus_name_to_delete}...\")\n",
    "        try:\n",
    "            # Optional: You might want to double-check existence before deleting\n",
    "            # rag.get_corpus(name=corpus_name_to_delete)\n",
    "            rag.delete_corpus(name=corpus_name_to_delete, force=True) # Use force=True to delete non-empty corpora\n",
    "            print(f\"  Successfully deleted {corpus_name_to_delete}\")\n",
    "            deleted_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"  Failed to delete {corpus_name_to_delete}: {e}\")\n",
    "            failed_count += 1\n",
    "    print(f\"\\nDeletion complete. Deleted: {deleted_count}, Failed: {failed_count}\")\n",
    "\n",
    "\n",
    "def create_rag_corpora(display_name, source_bucket):\n",
    "    EMBEDDING_MODEL = \"publishers/google/models/text-embedding-004\"  # @param {type:\"string\", isTemplate: true}\n",
    "    embedding_model_config = rag.EmbeddingModelConfig(publisher_model=EMBEDDING_MODEL)\n",
    "\n",
    "    rag_corpus = rag.create_corpus(\n",
    "        display_name=display_name, embedding_model_config=embedding_model_config\n",
    "    )\n",
    "    \n",
    "\n",
    "    \n",
    "    INPUT_GCS_BUCKET = (\n",
    "        source_bucket\n",
    "    )\n",
    "\n",
    "    response = rag.import_files(\n",
    "        corpus_name=rag_corpus.name,\n",
    "        paths=[INPUT_GCS_BUCKET],\n",
    "        chunk_size=1024,  # Optional\n",
    "        chunk_overlap=100,  # Optional\n",
    "        max_embedding_requests_per_min=900,  # Optional\n",
    "    )\n",
    "    \n",
    "    # This code shows how to upload local files to the corpus. \n",
    "    #rag_file = rag.upload_file(\n",
    "    #    corpus_name=rag_corpus.name,\n",
    "    #    path=\"./test.txt\",\n",
    "    #    display_name=\"test.txt\",\n",
    "    #    description=\"my test file\"\n",
    "    #)\n",
    "    \n",
    "    return rag_corpus\n",
    "\n",
    "    \n",
    "\n",
    "print(\"RAG corpus management functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "tool-funcs-code",
   "metadata": {
    "Collapsed": "false",
    "jupyter": {
     "source_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Define Tool Functions (Ticketing, File Handling, RAG Query)\n",
    "\n",
    "# --- Ticketing Tools ---\n",
    "\n",
    "def create_ticket(ticket_data: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Creates a ticket via the /ticket endpoint.\n",
    "\n",
    "    Args:\n",
    "        ticket_data: A dictionary containing the ticket data\n",
    "                     (ticket_id, description, customer_id, contact_name).\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the API response.  Handles errors gracefully.\n",
    "    \"\"\"\n",
    "    url = f\"{ticket_server_url}/ticket\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(ticket_data))\n",
    "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"error\": f\"Request failed: {e}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd3934e2-d076-47d6-bbfd-40fe9bc4fbc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_note(ticket_id: int, contact_name: str, note: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Adds a note to a ticket via the API's /notes endpoint.\n",
    "\n",
    "    Sends the provided ticket details as JSON to the API and returns\n",
    "    the parsed JSON response from the server.\n",
    "\n",
    "    Args:\n",
    "        ticket_id: int - The ID number of the ticket.\n",
    "        contact_name: str - The name of the contact person.\n",
    "        note: str - The content of the note to add.\n",
    "\n",
    "    Returns:\n",
    "         Dict[str, Any]:\n",
    "            - On success: A dictionary representing the parsed JSON response\n",
    "              from the API (content depends on the specific API implementation,\n",
    "              often includes details of the created note or a success status).\n",
    "            - On failure (request exception or non-2xx HTTP status):\n",
    "              A dictionary containing an 'error' key with a description of the failure,\n",
    "              e.g., {\"error\": \"Request failed: 404 Client Error: Not Found for url: ...\"}.\n",
    "    \"\"\"\n",
    "    url = f\"{ticket_server_url}/notes\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    # Construct the dictionary *inside* the function\n",
    "    note_data = {\n",
    "        \"ticket_id\": ticket_id,\n",
    "        \"contact_name\": contact_name,\n",
    "        \"note\": note\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(note_data))\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"error\": f\"Request failed: {e}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77059349-dfee-420b-a8e6-13260d78d855",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_file_to_session(uri: str) -> str:\n",
    "    \"\"\"\n",
    "    Adds a specific file from Google Cloud Storage (GCS) to the current session state for agent processing.\n",
    "\n",
    "    This function takes a GCS URI for a file and wraps it in a `types.Content` object.\n",
    "    This object is then typically used to make the file's content accessible to the\n",
    "    agent for tasks like summarization, question answering, or data extraction\n",
    "    related specifically to that file within the ongoing conversation or session.\n",
    "    The MIME type is assumed to be inferred by the underlying system or defaults.\n",
    "\n",
    "    Use this function *after* you have identified a specific GCS URI (e.g., using\n",
    "    `get_gcs_uri` or similar) that you need the agent to analyze or reference directly.\n",
    "\n",
    "    Args:\n",
    "        uri: str - The complete Google Cloud Storage URI of the file to add.\n",
    "                 Must be in the format \"gs://bucket_name/path/to/file.pdf\".\n",
    "                 Example: \"gs://my-doc-bucket/reports/q1_report.pdf\"\n",
    "\n",
    "    Returns:\n",
    "         types.Content - A structured Content object representing the referenced file.\n",
    "                       This object has `role='user'` and contains a `types.Part`\n",
    "                       that holds the reference to the provided GCS URI.\n",
    "                       This Content object can be passed to the agent in subsequent calls.\n",
    "    \"\"\"\n",
    "    print(uri)\n",
    "    content = types.Content(\n",
    "        role='user',\n",
    "        parts=[\n",
    "            # Try passing ONLY the uri positionally, based on the error message \"takes 1 positional argument\"\n",
    "            types.Part.from_uri(\n",
    "                file_uri=uri,\n",
    "                mime_type=\"application/pdf\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7583542d-bdd9-4d81-aec5-55ff66dbb9ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_gcs_uri(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves Google Cloud Storage (GCS) URIs for documents relevant to a given query.\n",
    "\n",
    "    This function queries a pre-configured Retrieval-Augmented Generation (RAG)\n",
    "    corpus to find documents related to the input query string. It extracts\n",
    "    the source GCS URIs from the top relevant documents identified by the\n",
    "    RAG system based on semantic similarity. Use this function when you need\n",
    "    to find the source files in GCS that contain information related to a\n",
    "    specific question or topic.\n",
    "\n",
    "    Args:\n",
    "        query: str - The natural language query or topic to search for within\n",
    "                 the RAG corpus. For example: \"What were the Q3 sales figures?\"\n",
    "                 or \"Tell me about project Alpha's latest status\".\n",
    "\n",
    "    Returns:\n",
    "         str - A JSON string representing a list of unique GCS URIs. These URIs\n",
    "               point to the source documents found to be relevant to the query.\n",
    "               Returns a JSON string representing an empty list ('[]') if no\n",
    "               relevant documents meet the similarity criteria.\n",
    "               Example return value: '[\"gs://my-bucket/doc1.pdf\", \"gs://my-bucket/report_q3.txt\"]'\n",
    "    \"\"\"\n",
    "    query_response = rag.retrieval_query(\n",
    "        rag_resources=[\n",
    "            rag.RagResource(\n",
    "                rag_corpus=rag_corpus.name,\n",
    "                # Optional: supply IDs from `rag.list_files()`.\n",
    "                # rag_file_ids=[\"rag-file-1\", \"rag-file-2\", ...],\n",
    "            )\n",
    "        ],\n",
    "        text=f'''\n",
    "        {query}\n",
    "        ''',\n",
    "        similarity_top_k=10,  # Optional\n",
    "        vector_distance_threshold=0.5,  # Optional\n",
    "    )\n",
    "    #print(response)\n",
    "    uri_set = set()\n",
    "    for context in query_response.contexts.contexts:\n",
    "        uri_set.add(context.source_uri)\n",
    "        #json.dumps(list(uri_set))\n",
    "    #doc_uri = uri_set.pop()\n",
    "    doc_uri = json.dumps(list(uri_set))\n",
    "    return doc_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rag-setup-markdown",
   "metadata": {},
   "source": [
    "## 6. RAG Corpus Setup\n",
    "\n",
    "Check if the RAG Corpus configured in step 2 exists. If not, create it and initiate file import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "rag-setup-code",
   "metadata": {
    "Collapsed": "false",
    "jupyter": {
     "source_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListRagCorporaPager<rag_corpora {\n",
      "  name: \"projects/YOUR_PROJECT_ID/locations/us-central1/ragCorpora/6512768011131158528\"\n",
      "  display_name: \"nest-rag-corpus\"\n",
      "  create_time {\n",
      "    seconds: 1745333337\n",
      "    nanos: 950261000\n",
      "  }\n",
      "  update_time {\n",
      "    seconds: 1745333337\n",
      "    nanos: 950261000\n",
      "  }\n",
      "  rag_embedding_model_config {\n",
      "    vertex_prediction_endpoint {\n",
      "      endpoint: \"projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/text-embedding-004\"\n",
      "    }\n",
      "  }\n",
      "  rag_vector_db_config {\n",
      "    rag_managed_db {\n",
      "    }\n",
      "    rag_embedding_model_config {\n",
      "      vertex_prediction_endpoint {\n",
      "        endpoint: \"projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/text-embedding-004\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  corpus_status {\n",
      "    state: ACTIVE\n",
      "  }\n",
      "  vector_db_config {\n",
      "    rag_managed_db {\n",
      "    }\n",
      "    rag_embedding_model_config {\n",
      "      vertex_prediction_endpoint {\n",
      "        endpoint: \"projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/text-embedding-004\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  rag_files_count: 3\n",
      "}\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "existing_corpora = rag.list_corpora()\n",
    "\n",
    "print(existing_corpora)\n",
    "\n",
    "# Variable to hold the corpus if found\n",
    "found_corpus = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcf7c1db-1fa8-4247-8e61-28c96efa9060",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing Corpa found. Using projects/YOUR_PROJECT_ID/locations/us-central1/ragCorpora/6512768011131158528\n",
      "This corpus contains the following files:\n",
      "nest-thermostat-e-install-guide.pdf\n",
      "Nest_Power_Connector_Installation_Guide.pdf\n",
      "nest-thermostat-gen3-install-guide-US.pdf\n",
      "\n",
      "Proceeding with corpus: projects/YOUR_PROJECT_ID/locations/us-central1/ragCorpora/6512768011131158528\n"
     ]
    }
   ],
   "source": [
    "# Iterate through all existing RAG corpora\n",
    "for corpus in existing_corpora.rag_corpora: # Ensure you iterate the correct attribute\n",
    "    # Check if display_name exists and matches\n",
    "    if getattr(corpus, 'display_name', None) == corpa_name:\n",
    "        print(f\"Existing Corpa found. Using {corpus.name}\")\n",
    "        \n",
    "        # You already have the corpus object, no need to call get_corpus usually\n",
    "        # If 'corpus' object from the list is sufficient, use it directly.\n",
    "        # If you MUST get a fresh object or different type, uncomment the next line:\n",
    "        # rag_corpus = rag.get_corpus(name=corpus.name) \n",
    "        found_corpus = corpus # Store the found corpus object\n",
    "        \n",
    "        print(f\"This corpus contains the following files:\")\n",
    "        try:\n",
    "            # List files associated with the found corpus\n",
    "            for file in rag.list_files(corpus.name): # Use corpus.name\n",
    "                print(getattr(file, 'display_name', 'N/A')) # Safer access\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not list files for {corpus.name}. Error: {e}\")\n",
    "            \n",
    "        break # Exit the loop as soon as we find the match\n",
    "\n",
    "# After the loop, check if we found anything\n",
    "if found_corpus is None:\n",
    "    # The loop completed without finding the corpus\n",
    "    print(f\"No existing {corpa_name} resource found. Creating one now.\")\n",
    "    try:\n",
    "        rag_corpus = create_rag_corpora(corpa_name, corpa_document_bucket)\n",
    "        print(f\"New RAG corpus created at {rag_corpus.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating corpus {corpa_name}: {e}\")\n",
    "        rag_corpus = None # Indicate failure\n",
    "else:\n",
    "    # The corpus was found in the loop\n",
    "    rag_corpus = found_corpus # Assign the found corpus to the main variable\n",
    "\n",
    "# Now 'rag_corpus' holds either the found or newly created corpus (or None if creation failed)\n",
    "# You can proceed to use 'rag_corpus' here\n",
    "if rag_corpus:\n",
    "    print(f\"\\nProceeding with corpus: {rag_corpus.name}\")\n",
    "    # ... your next steps using rag_corpus ...\n",
    "else:\n",
    "    print(f\"\\nFailed to find or create corpus '{corpa_name}'. Cannot proceed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab536faa-9525-48ed-b4f4-5be0ebded05c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = get_gcs_uri('How do I install a Nest E thermostat')\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "define-subagents-markdown",
   "metadata": {},
   "source": [
    "## 8. Define Sub-Agents\n",
    "\n",
    "Define the specialized agents:\n",
    "1.  `rag_agent`: Finds relevant documents using the RAG tool.\n",
    "2.  `reasoning_agent`: Outlines troubleshooting steps based on provided documents.\n",
    "3.  `notes_agent`: Adds notes to the ticketing system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-rag-agent-code",
   "metadata": {
    "Collapsed": "false",
    "jupyter": {
     "source_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- RAG Agent ---\n",
    "rag_agent = None\n",
    "try:\n",
    "    rag_agent = Agent(\n",
    "        model=\"gemini-2.0-flash-001\",\n",
    "        name=\"rag_agent\",\n",
    "        instruction=\n",
    "        \"\"\"\n",
    "          You are a customer support agent. You help locate documentation that will resolve customer issues.\n",
    "          Identify the most relevant support document that pertains to the question.\n",
    "          Your job is to only provide the GCS URI for the closest matching document, not to resolve the issue.\n",
    "          You will use the get_gcs_uri to identify the correct file. \n",
    "          The response from get_gcs_uri will be a text string like 'gs://bucket_name/folder/file 1.pdf'\n",
    "          Determine which files are relevant to the customer's question and return them to the root agent.\n",
    "        \"\"\",\n",
    "        description=\"Retrieves information from a RAG Engine instance and returns the GCS URI of relevant files.\",\n",
    "        tools=[\n",
    "            get_gcs_uri\n",
    "        ],\n",
    "    )\n",
    "    print(f\"✅ Agent '{rag_agent.name}' created.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Could not create Greeting agent. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-reasoning-agent-code",
   "metadata": {
    "Collapsed": "false",
    "jupyter": {
     "source_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -- Reasoning Agent ---\n",
    "reasoning_agent = None\n",
    "try:\n",
    "    reasoning_agent = Agent(\n",
    "        #model=\"gemini-2.5-pro-exp-03-25\", # Using a different model to account for potential resource constraints\n",
    "        model=\"gemini-2.5-flash-preview-04-17\",\n",
    "        name=\"reasoning_agent\",\n",
    "        instruction=\n",
    "        \"\"\"\n",
    "          You are a customer support agent. You help define the troubleshooting process to resolve customer issues.\n",
    "          Use the information in the document to define the process for resolving the issue.\n",
    "          Once the files have been added to your context, use that information to outline the process needed to resolve the identified problem.\n",
    "          If multiple documents are provided, specify which document or documents contains the relevant information to resolve the issue.\n",
    "          The process needs to outline the activities for the Nest technical support representitive to perform.\n",
    "          The notes system only supports plain text. Ensure you only use text in your output.\n",
    "      \n",
    "          Example:\n",
    "          Step 1: Do this\n",
    "          Step 2: Do this other task\n",
    "          Step 3: etc\n",
    "        \"\"\",\n",
    "        description=\"Defines the troubleshooting process to help resolve the customer's problem\",\n",
    "        tools=[\n",
    "            #add_file_to_session,\n",
    "        ],\n",
    "    )\n",
    "    print(f\"✅ Agent '{reasoning_agent.name}' created.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Could not create Greeting agent. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-notes-agent-code",
   "metadata": {
    "Collapsed": "false",
    "jupyter": {
     "source_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Notest Agent ---\n",
    "notes_agent = None\n",
    "try:\n",
    "    notes_agent = Agent(\n",
    "        model=\"gemini-2.0-flash-001\",\n",
    "        name=\"notes_agent\",\n",
    "        instruction=\"\"\"\n",
    "            You are a customer support assistant agent. Your primary task is to generate informative and well-structured notes for customer support tickets. \n",
    "            These notes will be added to the ticket's history and used by customer support representatives to understand the issue, track progress, and provide consistent service.\n",
    "            Step 1: Check if you have the user's ticket ID and contact name (you can use their provided name or email as contact name). If not, politely ask for the informaiton you are missing.\n",
    "            Step 2: Once you have the ticket ID, contact name, and the troubleshooting steps, use the 'add_note' tool to add the notes to the ticket.\n",
    "            Step 3: Confirm to the user that the ticket has been updated with the troubleshooting plan.\n",
    "            Step 4: Thank the customer for their time and to have a nice day.\n",
    "        \"\"\",\n",
    "        description=\"Add notes to the associated ticket\",\n",
    "        tools=[\n",
    "            add_note,\n",
    "        ],\n",
    "    )\n",
    "    print(f\"✅ Agent '{notes_agent.name}' created.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Could not create Greeting agent. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "define-root-agent-markdown",
   "metadata": {},
   "source": [
    "## 9. Define Root Agent\n",
    "\n",
    "Define the main orchestrator agent (`nest_agent_team`) that coordinates the sub-agents and uses the `add_file_to_session` tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-root-agent-code",
   "metadata": {
    "Collapsed": "false",
    "jupyter": {
     "source_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Define the Root Agent with Sub-Agents\n",
    "\n",
    "# Ensure sub-agents were created successfully before defining the root agent.\n",
    "# Also ensure the original 'get_weather' tool is defined.\n",
    "root_agent = None\n",
    "runner_root = None # Initialize runner\n",
    "\n",
    "if rag_agent and reasoning_agent and notes_agent and 'add_file_to_session' in globals():\n",
    "    # Let's use a capable Gemini model for the root agent to handle orchestration\n",
    "    root_agent_model = 'gemini-2.0-flash-001'\n",
    "        \n",
    "    nest_agent_team = Agent(\n",
    "        name=\"nest_support_agent\",\n",
    "        model=\"gemini-2.0-flash-001\",\n",
    "        description=\"The main coordinator agent. Handles user requests and delegates tasks to specialists.\",\n",
    "        instruction=\n",
    "        \"\"\"\n",
    "            You are the lead Nest customer support coordinator agent. Your goal is to understand the customer's issue, find relevant documentation, generate a troubleshooting plan, and log the plan into their support ticket.\n",
    "\n",
    "            You have access to specialized tools and sub-agents:\n",
    "            1. Tool `add_file_to_session`: Use this tool *after* getting GCS URIs. Provide ONE GCS URI (e.g., \"gs://bucket/doc.pdf\") to this tool. The tool prepares the file content for context. Call this tool for EACH relevant URI returned by the rag_agent.\n",
    "            2. Sub-Agent `rag_agent`: Call this agent first with the user's problem description to get a JSON list of relevant GCS document URIs.\n",
    "            3. Sub-Agent `reasoning_agent`: Call this agent *after* using `add_file_to_session` for all relevant URIs. Provide the user's problem and indicate that the relevant documents are now in context. This agent will return the troubleshooting steps.\n",
    "            4. Sub-Agent `notes_agent`: Call this agent last. You need the `ticket_id` (integer), `contact_name` (string, use your name \"Nest Support Agent\"), and the `note` (string, the troubleshooting steps from reasoning_agent). Ask the user for their ticket ID and name/email if you don't have it.\n",
    "\n",
    "            Follow these steps precisely:\n",
    "            Step 1: Greet the user and understand their Nest product issue.\n",
    "            Step 2: Respond to the customer with an acknowledgement of the question and politely ask the customer to please wait while you research the answer.\n",
    "            Step 3: Call the `rag_agent` with the user's issue description. Extract the GCS URIs from the JSON list it returns.\n",
    "            Step 4: If URIs are found:\n",
    "                - For EACH URI in the list, call the `add_file_to_session` tool with that single URI. Acknowledge to yourself or briefly mention you're processing the file.\n",
    "            Step 5: After processing all relevant files, call the `reasoning_agent`. Provide the user's original problem description and explicitly state that the necessary documents are in the context. Capture the troubleshooting steps it returns.\n",
    "            Step 6: Acknowledge to the user that you have the troubleshooting steps and provide a short summary to the customer.\n",
    "            \"\"\",\n",
    "        tools=[\n",
    "            add_file_to_session,\n",
    "            AgentTool(agent=rag_agent), \n",
    "            AgentTool(agent=reasoning_agent)],\n",
    "        sub_agents=[notes_agent]\n",
    "    )\n",
    "    print(f\"✅ Root Agent '{nest_agent_team.name}' created using model '{root_agent_model}' with sub-agents: {[sa.name for sa in nest_agent_team.sub_agents]}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Cannot create root agent because one or more sub-agents failed to initialize or 'add_file_to_session' tool is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interact-markdown",
   "metadata": {},
   "source": [
    "## 10. Interact with the Agent Team\n",
    "\n",
    "Now, set up the runner and session management to interact with the defined agent team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interact-code",
   "metadata": {
    "Collapsed": "false",
    "jupyter": {
     "source_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Run Conversation with the Agent Team\n",
    "\n",
    "# Ensure the root agent (e.g., 'nest_agent_team' or 'root_agent' from the previous cell) is defined.\n",
    "# Ensure the call_agent_async function is defined.\n",
    "\n",
    "# Check if the root agent variable exists before defining the conversation function\n",
    "root_agent_var_name = 'root_agent' # Default name from Step 3 guide\n",
    "if 'nest_agent_team' in globals(): # Check if user used this name instead\n",
    "    root_agent_var_name = 'nest_agent_team'\n",
    "elif 'root_agent' not in globals():\n",
    "    print(\"⚠️ Root agent ('root_agent' or 'nest_agent_team') not found. Cannot define run_team_conversation.\")\n",
    "    # Assign a dummy value to prevent NameError later if the code block runs anyway\n",
    "    root_agent = None\n",
    "\n",
    "if root_agent_var_name in globals() and globals()[root_agent_var_name]:\n",
    "    async def run_team_conversation():\n",
    "        print(\"\\n--- Testing Agent Team Delegation ---\")\n",
    "        # InMemorySessionService is simple, non-persistent storage for this tutorial.\n",
    "        session_service = InMemorySessionService()\n",
    "\n",
    "        # Define constants for identifying the interaction context\n",
    "        APP_NAME = \"nets_support_agent_team\"\n",
    "        USER_ID = \"user_1_agent_team\"\n",
    "        SESSION_ID = \"session_001_agent_team\" # Using a fixed ID for simplicity\n",
    "\n",
    "        # Create the specific session where the conversation will happen\n",
    "        session = session_service.create_session(\n",
    "            app_name=APP_NAME,\n",
    "            user_id=USER_ID,\n",
    "            session_id=SESSION_ID\n",
    "        )\n",
    "        print(f\"Session created: App='{APP_NAME}', User='{USER_ID}', Session='{SESSION_ID}'\")\n",
    "\n",
    "        # --- Get the actual root agent object ---\n",
    "        # Use the determined variable name\n",
    "        actual_root_agent = globals()[root_agent_var_name]\n",
    "\n",
    "        # Create a runner specific to this agent team test\n",
    "        runner = Runner(\n",
    "            agent=actual_root_agent, # Use the root agent object\n",
    "            app_name=APP_NAME,       # Use the specific app name\n",
    "            session_service=session_service # Use the specific session service\n",
    "            )\n",
    "        # Corrected print statement to show the actual root agent's name\n",
    "        print(f\"Runner created for agent '{actual_root_agent.name}'.\")\n",
    "\n",
    "        # Always interact via the root agent's runner, passing the correct IDs\n",
    "        await call_agent_async(query = \"Hello there!\", runner=runner, user_id=USER_ID, session_id=SESSION_ID)\n",
    "        await call_agent_async(query = \"I need to know how to setup my nest gen 3 unit.\", runner=runner, user_id=USER_ID, session_id=SESSION_ID)\n",
    "        await call_agent_async(query = \"My name is John Doe and email is johnDoe@here.com. My ticket number is 132436.\", runner=runner, user_id=USER_ID, session_id=SESSION_ID)\n",
    "        await call_agent_async(query = \"Great, thank you!\", runner=runner, user_id=USER_ID, session_id=SESSION_ID)\n",
    "\n",
    "    # Execute the conversation\n",
    "    # Note: This may require API keys for the models used by root and sub-agents!\n",
    "    #asyncio.run(run_team_conversation())\n",
    "    print(\"Attempting execution using 'await' (default for notebooks)...\")\n",
    "    await run_team_conversation()\n",
    "else:\n",
    "    print(\"\\n⚠️ Skipping agent team conversation as the root agent was not successfully defined in the previous step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-markdown",
   "metadata": {},
   "source": [
    "## 11. Cleanup (Optional)\n",
    "\n",
    "If you want to delete the RAG Corpus created during this session, uncomment and run the following cell. **Warning:** This permanently deletes the corpus and its indexed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup-code",
   "metadata": {
    "Collapsed": "false",
    "jupyter": {
     "source_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Delete the RAG Corpus (USE WITH CAUTION!)\n",
    "\n",
    "# Set this flag to True only if you are sure you want to delete the corpus\n",
    "confirm_delete = False\n",
    "\n",
    "if confirm_delete and 'rag_corpus_resource_name' in globals() and rag_corpus_resource_name:\n",
    "    print(f\"Attempting to delete RAG Corpus: {rag_corpus_resource_name} ({corpa_name})\")\n",
    "    try:\n",
    "        # We need the pager object for the delete function as written, but it's simpler\n",
    "        # to delete directly by name if we know it.\n",
    "        # Let's delete directly using the resource name.\n",
    "        rag.delete_corpus(name=rag_corpus_resource_name, force=True) # force=True deletes even if not empty\n",
    "        print(f\"Successfully deleted corpus: {rag_corpus_resource_name}\")\n",
    "        rag_corpus = None\n",
    "        rag_corpus_resource_name = \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to delete corpus {rag_corpus_resource_name}: {e}\")\n",
    "elif not ('rag_corpus_resource_name' in globals() and rag_corpus_resource_name):\n",
    "    print(\"Skipping deletion: RAG corpus resource name is not set.\")\n",
    "else:\n",
    "    print(\"Skipping deletion: confirm_delete is set to False.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da45fe7a-322c-426b-8d01-ece7d4ec5ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-agent-framework-agent-framework",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "agent-framework",
   "language": "python",
   "name": "conda-env-agent-framework-agent-framework"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
